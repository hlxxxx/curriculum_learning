# æ¢ç©¶è¯¾ç¨‹å­¦ä¹ å¯¹å¤§æ¨¡å‹è§£é¢˜èƒ½åŠ›çš„å½±å“

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªå®Œæ•´çš„ã€Œè¯¾ç¨‹å­¦ä¹ ï¼ˆCurriculum Learningï¼‰ã€é©±åŠ¨çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆGLM-Z1ï¼‰å‚æ•°é«˜æ•ˆå¾®è°ƒæ¡†æ¶ï¼Œç”¨äºæ•°å­¦ç±»æ¨ç†ä»»åŠ¡ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†æ•°å­¦é¢˜ç›®æŒ‰ç…§éš¾åº¦ï¼ˆLevel 1 è‡³ Level 5ï¼‰åˆ†é˜¶æ®µè®­ç»ƒï¼Œå®ç°æ¨¡å‹ä»æ˜“åˆ°éš¾é€æ­¥é€‚åº”å¤æ‚æ¨ç†ä»»åŠ¡ã€‚è¯¥æ¡†æ¶æ”¯æŒ LoRA å¾®è°ƒã€æ··åˆç²¾åº¦è®­ç»ƒã€æ•°æ®é‡æ”¾æœºåˆ¶å’Œç»“æ„åŒ–è¯„ä¼°ã€‚

---

## ğŸ”§ é¡¹ç›®ç»“æ„è¯´æ˜

```
.
â”œâ”€â”€ config.py              # è®­ç»ƒé…ç½®ç±»
â”œâ”€â”€ curriculum.py          # æ„å»ºè¯¾ç¨‹ï¼ˆåˆ†é˜¶æ®µï¼‰æ•°æ®
â”œâ”€â”€ data.py                # æ•°æ®åŠ è½½ã€åˆ†ç»„ä¸ç¼–ç 
â”œâ”€â”€ evaluate.py            # æ¨¡å‹è¯„ä¼°è„šæœ¬
â”œâ”€â”€ models.py              # æ¨¡å‹åŠ è½½ + LoRA æ³¨å…¥
â”œâ”€â”€ trainer.py             # ä¸»è®­ç»ƒå¾ªç¯ï¼ˆå«é‡æ”¾æœºåˆ¶ï¼‰
â”œâ”€â”€ train.py               # è®­ç»ƒä¸»å…¥å£
â”œâ”€â”€ split_dataset.py       # æ•°æ®é›†åˆ‡åˆ†ï¼ˆå¸¦åˆ†å±‚ä¿è¯ï¼‰
â””â”€â”€ dataset/
    â””â”€â”€ split_dataset/
        â”œâ”€â”€ train.parquet
        â””â”€â”€ test.parquet
```

---

## ä¾èµ–ç¯å¢ƒå®‰è£…

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…ä¾èµ–é¡¹ï¼š

```bash
pip install -r requirements.txt
```

ä¸»è¦ä¾èµ–åŒ…æ‹¬ï¼š

- `transformers`
- `peft`
- `accelerate`
- `datasets`
- `pyarrow`
- `sympy`
- `tqdm`
- `modelscope`

---

## æ•°æ®æ ¼å¼ä¸å¤„ç†

ä½¿ç”¨ HuggingFace ä¸Šçš„ [competition_math](https://huggingface.co/datasets/qwedsacf/competition_math) æ•°æ®é›†æˆ–è‡ªå®šä¹‰ `.parquet` æ–‡ä»¶ï¼Œå­—æ®µåŒ…æ‹¬ï¼š

```json
{
  "problem": "é¢˜ç›®æè¿°",
  "solution": "æ ‡å‡†è§£ç­”",
  "level": "Level 1" è‡³ "Level 5",
  "type": "Algebra" / "Counting & Probability" / ...
}
```

å¯ä½¿ç”¨ `split_dataset.py` è¿›è¡Œå±‚çº§åˆ†å±‚åˆ’åˆ†ï¼Œç”Ÿæˆ `train.parquet` å’Œ `test.parquet` æ–‡ä»¶ã€‚

---

## å¯åŠ¨è®­ç»ƒï¼ˆè¯¾ç¨‹å­¦ä¹ ï¼‰

ç¤ºä¾‹å‘½ä»¤å¦‚ä¸‹ï¼ˆé»˜è®¤ä» Level 1 åˆ° Level 5ï¼‰ï¼š

```bash
python train.py   --model_name ./pretrained/zai-org/GLM-Z1-9B-0414   --output_dir ./outputs_glm_z1_math   --max_length 1024   --batch_size 4   --learning_rate 2e-4   --num_epochs_per_level 1   --max_train_samples_per_level 1000   --use_level
```

æ¯ä¸ª level ä¼šå•ç‹¬è®­ç»ƒè‹¥å¹² epochï¼Œå¹¶å°†æ ·æœ¬åŠ å…¥ replay buffer ä¿æŒå†å²è®°å¿†ï¼Œé¿å…â€œç¾éš¾æ€§é—å¿˜â€ã€‚

---

## æ¨¡å‹è¯„ä¼°

æ¨¡å‹è¯„ä¼°æ”¯æŒä¸¤ä¸ªæ•°æ®é›†ï¼š

- `competition_math`
- `combicbench`ï¼ˆç»„åˆæ•°å­¦é¢˜ï¼‰

è¯„ä¼°å‘½ä»¤å¦‚ä¸‹ï¼š

```bash
python evaluate.py   --model_name ./pretrained/zai-org/GLM-Z1-9B-0414   --eval_model_path ./outputs_glm_z1_math/checkpoint_last   --eval_dataset_name competition_math   --eval_dataset_file ./dataset/split_dataset/test.parquet   --eval_output_file eval_results.jsonl   --batch_size 4   --max_new_tokens 512
```

è¯„ä¼°æ–¹å¼åŒ…æ‹¬ï¼š

- ä¸¥æ ¼å­—ç¬¦ä¸²åŒ¹é…
- æ•°å­¦è¡¨è¾¾å¼ç­‰ä»·ï¼ˆä½¿ç”¨ SymPy åˆ¤æ–­ï¼‰
- æ•°å€¼è¿‘ä¼¼åˆ¤æ–­ï¼ˆæµ®ç‚¹å®¹å·®ï¼‰

---

## LoRA å‚æ•°æ³¨å…¥è¯´æ˜

é¡¹ç›®é‡‡ç”¨ LoRA è¿›è¡Œå¾®è°ƒï¼Œä»…å¯¹éƒ¨åˆ†å‚æ•°æ³¨å…¥æƒé‡ï¼Œç›®æ ‡æ¨¡å—åŒ…æ‹¬ï¼š

```python
["q_proj", "k_proj", "v_proj", "o_proj", "gate_up_proj", "down_proj"]
```

LoRA é…ç½®ç¤ºä¾‹ï¼š

```python
LoraConfig(
  r=64,
  lora_alpha=128,
  lora_dropout=0.05,
  target_modules=...,
  task_type="CAUSAL_LM"
)
```

---

## æ¨¡å‹ä¿å­˜ä¸é‡å¯

- æ¯ä¸ª level çš„è®­ç»ƒç»“æœä¿å­˜åœ¨ `outputs_glm_z1_math/level_LevelX/`
- æ‰€æœ‰è®­ç»ƒé˜¶æ®µçš„æœ€ç»ˆ checkpoint ä¿å­˜åœ¨ `outputs_glm_z1_math/checkpoint_last/`
- å¯ä¸­æ–­æ¢å¤è®­ç»ƒï¼ˆæ–­ç‚¹ç»­è®­ï¼‰ï¼Œè‡ªåŠ¨è®°å½•å½“å‰ level ä¸ step ä¿¡æ¯

---

## Replay Buffer æœºåˆ¶

æ¯æ¬¡è®­ç»ƒæ–° level æ—¶ï¼Œä¼šå¼•å…¥ä¸€å®šæ¯”ä¾‹ï¼ˆé»˜è®¤ 30%ï¼‰çš„å†å²æ ·æœ¬ï¼ˆæœ€å¤§ 5000 æ¡ï¼‰è¿›è¡Œæ··åˆè®­ç»ƒï¼Œé˜²æ­¢æ¨¡å‹â€œé—å¿˜â€å‰æœŸå­¦ä¹ å†…å®¹ã€‚

---

## å¼€å‘å»ºè®®

- ä¿®æ”¹ `config.py` ä¸­çš„ `level_order` å¯æ§åˆ¶è®­ç»ƒé¡ºåºï¼ˆä¾‹å¦‚åå‘è®­ç»ƒï¼‰
- æ”¯æŒ resume_from_checkpoint å‚æ•°è¿›è¡Œè®­ç»ƒæ–­ç‚¹æ¢å¤
- å¯æ¥å…¥ CombiBench æ•°æ®é›†åšæ³›åŒ–èƒ½åŠ›æµ‹è¯•

